{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8428283,
          "sourceType": "datasetVersion",
          "datasetId": 5007639
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install jupyterlab jupyterlab-optuna"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-05-16T13:11:21.418322Z",
          "iopub.execute_input": "2024-05-16T13:11:21.418838Z",
          "iopub.status.idle": "2024-05-16T13:11:37.744022Z",
          "shell.execute_reply.started": "2024-05-16T13:11:21.418804Z",
          "shell.execute_reply": "2024-05-16T13:11:37.742736Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nxa4PPfkcHI",
        "outputId": "6242351f-5259-42a8-d8c0-3892b8075910"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jupyterlab\n",
            "  Downloading jupyterlab-4.2.3-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyterlab-optuna\n",
            "  Downloading jupyterlab_optuna-0.1.0.tar.gz (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab)\n",
            "  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Collecting httpx>=0.25.0 (from jupyterlab)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Collecting ipykernel>=6.5.0 (from jupyterlab)\n",
            "  Using cached ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab)\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab)\n",
            "  Using cached jupyter_server-2.14.1-py3-none-any.whl (383 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab)\n",
            "  Using cached jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (24.1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (67.7.2)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (2.0.1)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (6.3.3)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from jupyterlab) (5.7.1)\n",
            "Collecting optuna-dashboard (from jupyterlab-optuna)\n",
            "  Downloading optuna_dashboard-0.15.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from async-lru>=1.0.0->jupyterlab) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab)\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=6.5.0->jupyterlab)\n",
            "  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=6.5.0->jupyterlab) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3.0.3->jupyterlab) (2.1.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterlab) (4.2.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab)\n",
            "  Using cached jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.20.0)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.15.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached json5-0.9.25-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (4.19.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab) (2.31.0)\n",
            "Collecting bottle (from optuna-dashboard->jupyterlab-optuna)\n",
            "  Downloading bottle-0.12.25-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna>=3.1.0 (from optuna-dashboard->jupyterlab-optuna)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard->jupyterlab-optuna) (1.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (0.18.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (2.8.2)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.1)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab)\n",
            "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.20.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna) (1.25.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab) (2.0.7)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard->jupyterlab-optuna) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard->jupyterlab-optuna) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard->jupyterlab-optuna) (3.5.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.8.4)\n",
            "Collecting fqdn (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting isoduration (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting uri-template (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab) (24.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.5.0->jupyterlab) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1.0->optuna-dashboard->jupyterlab-optuna) (3.0.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab)\n",
            "  Using cached types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: jupyterlab-optuna\n",
            "  Building wheel for jupyterlab-optuna (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jupyterlab-optuna: filename=jupyterlab_optuna-0.1.0-py3-none-any.whl size=3607998 sha256=22d4eac9f381b857e2bb043868de3c50ff3ccf7910f023e0cbd972c3f7201385\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/9b/ca/eb4257d7ea94f5c94b3117fd9c2cb01076558ec93990308073\n",
            "Successfully built jupyterlab-optuna\n",
            "Installing collected packages: bottle, uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, overrides, Mako, jsonpointer, json5, jedi, h11, fqdn, comm, colorlog, async-lru, jupyter-server-terminals, jupyter-client, httpcore, arrow, alembic, optuna, isoduration, ipykernel, httpx, optuna-dashboard, jupyter-events, jupyter-server, jupyterlab-server, jupyterlab-optuna, jupyter-lsp, jupyterlab\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.4 which is incompatible.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 arrow-1.3.0 async-lru-2.0.4 bottle-0.12.25 colorlog-6.8.2 comm-0.2.2 fqdn-1.5.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 ipykernel-6.29.4 isoduration-20.11.0 jedi-0.19.1 json5-0.9.25 jsonpointer-3.0.0 jupyter-client-8.6.2 jupyter-events-0.10.0 jupyter-lsp-2.2.5 jupyter-server-2.14.1 jupyter-server-terminals-0.5.3 jupyterlab-4.2.3 jupyterlab-optuna-0.1.0 jupyterlab-server-2.27.2 optuna-3.6.1 optuna-dashboard-0.15.1 overrides-7.7.0 python-json-logger-2.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20240316 uri-template-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install optuna-dashboard"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-16T13:11:37.745909Z",
          "iopub.execute_input": "2024-05-16T13:11:37.746265Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HU3cY4rkcHP",
        "outputId": "6704e6ed-98b7-4427-e208-36658c077a3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna-dashboard in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: bottle in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (0.12.25)\n",
            "Requirement already satisfied: optuna>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (3.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (24.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from optuna-dashboard) (1.2.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (1.25.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1.0->optuna-dashboard) (6.0.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->optuna-dashboard) (3.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1.0->optuna-dashboard) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna>=3.1.0->optuna-dashboard) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "!pip install lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from optuna.visualization import plot_optimization_history"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfQsCB1jkcHP",
        "outputId": "b684586e-0ebc-43e6-f846-20852fcff71b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Clean_train.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "p4fgpaUpkcHR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df['text']\n",
        "y = df['target']"
      ],
      "metadata": {
        "trusted": true,
        "id": "hUktgqv-kcHS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "trusted": true,
        "id": "AsHh92SUkcHS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tfidf = tfidf_vectorizer.fit_transform(x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "65g9FD9QkcHT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_tfidf,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42 ,\n",
        "                                                    shuffle = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zPhlcRETkcHT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb = LGBMClassifier()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Dv0AWegqkcHU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define the search space for LightGBM\n",
        "    lgbm_params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
        "        # Add more hyperparameters to search here\n",
        "    }\n",
        "\n",
        "    # Train LightGBM model\n",
        "    lgb_model = LGBMClassifier(**lgbm_params)\n",
        "    lgb_model.fit(X_train, y_train)\n",
        "\n",
        "    # Define the search space for logistic regression\n",
        "    lr_params = {\n",
        "        'C': trial.suggest_float('C', 0.1, 10.0),\n",
        "        # Add more hyperparameters to search here\n",
        "    }\n",
        "\n",
        "    # Train logistic regression model\n",
        "    lr_model = LogisticRegression(**lr_params)\n",
        "    lr_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    lgb_pred = lgb_model.predict(X_valid)\n",
        "    lr_pred = lr_model.predict(X_valid)\n",
        "\n",
        "    # Compute accuracy\n",
        "    lgb_accuracy = accuracy_score(y_valid, lgb_pred)\n",
        "    lr_accuracy = accuracy_score(y_valid, lr_pred)\n",
        "\n",
        "    # Return the performance as the objective value to maximize\n",
        "    return lgb_accuracy + lr_accuracy\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "2-Qf6JkJkcHV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(x_tfidf, y, test_size=0.2, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_C4gZu3hkcHW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Optuna study and optimize\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwM6XoiakcHX",
        "outputId": "0218c1ac-8d43-4f60-ce14-1b51e02bb1e7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:06,853] A new study created in memory with name: no-name-53d50abd-f273-4432-ae41-6d7ea362a3e0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036693 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:09,274] Trial 0 finished with value: 1.571240971766251 and parameters: {'learning_rate': 0.06286821262065109, 'num_leaves': 57, 'C': 9.176007704988644}. Best is trial 0 with value: 1.571240971766251.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021783 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:11,071] Trial 1 finished with value: 1.5436638214051215 and parameters: {'learning_rate': 0.07150082148804313, 'num_leaves': 96, 'C': 0.19803005438106147}. Best is trial 0 with value: 1.571240971766251.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022426 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:12,751] Trial 2 finished with value: 1.5640183847669076 and parameters: {'learning_rate': 0.026317970514756164, 'num_leaves': 96, 'C': 1.2478868968646002}. Best is trial 0 with value: 1.571240971766251.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024803 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:14,503] Trial 3 finished with value: 1.5804333552199608 and parameters: {'learning_rate': 0.07961950929353762, 'num_leaves': 80, 'C': 3.9456705222638484}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:16,496] Trial 4 finished with value: 1.5745239658568613 and parameters: {'learning_rate': 0.0838177099742153, 'num_leaves': 66, 'C': 8.933111589009805}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023322 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:17,745] Trial 5 finished with value: 1.5732107682206173 and parameters: {'learning_rate': 0.05872757742210115, 'num_leaves': 38, 'C': 3.2925647133957523}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022462 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:19,216] Trial 6 finished with value: 1.5594221930400525 and parameters: {'learning_rate': 0.01959601266203493, 'num_leaves': 80, 'C': 3.0844468206410496}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037510 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:21,526] Trial 7 finished with value: 1.57715036112935 and parameters: {'learning_rate': 0.06731086196884159, 'num_leaves': 54, 'C': 1.8583687768146433}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035974 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:23,547] Trial 8 finished with value: 1.577806959947472 and parameters: {'learning_rate': 0.062352967829123994, 'num_leaves': 76, 'C': 7.175117429677378}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023966 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 11:28:24,213] Trial 9 finished with value: 1.5489166119500983 and parameters: {'learning_rate': 0.040027631946951144, 'num_leaves': 20, 'C': 0.3962151566968075}. Best is trial 3 with value: 1.5804333552199608.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "trusted": true,
        "id": "F97fGDOvkcHX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = LGBMClassifier(**best_params)\n",
        "lgb_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XJPV12_VkcHX",
        "outputId": "2a498b7f-1f7c-4996-e71f-770eaa9bc70e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: C\n",
            "[LightGBM] [Warning] Unknown parameter: C\n",
            "[LightGBM] [Info] Number of positive: 2622, number of negative: 3468\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036950 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 8984\n",
            "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 573\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430542 -> initscore=-0.279641\n",
            "[LightGBM] [Info] Start training from score -0.279641\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(C=3.9456705222638484, learning_rate=0.07961950929353762,\n",
              "               num_leaves=80)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(C=3.9456705222638484, learning_rate=0.07961950929353762,\n",
              "               num_leaves=80)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(C=3.9456705222638484, learning_rate=0.07961950929353762,\n",
              "               num_leaves=80)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(C=best_params['C'])\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "apt4pvLfkcHY",
        "outputId": "f530f2db-9646-45a5-e33e-1b3a7809bb7a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=3.9456705222638484)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=3.9456705222638484)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=3.9456705222638484)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models on test data\n",
        "lgb_test_pred = lgb_model.predict(x_test)\n",
        "lr_test_pred = lr_model.predict(x_test)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3jJrzN2kcHY",
        "outputId": "bb53db00-9736-4b57-8b64-9b7dfc2a487b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RPoNdPHvkcHY",
        "outputId": "58182a68-4922-4b85-fabf-fe8a24e052a4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"3adcb385-a522-427a-b84e-a49431f798d7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3adcb385-a522-427a-b84e-a49431f798d7\")) {                    Plotly.newPlot(                        \"3adcb385-a522-427a-b84e-a49431f798d7\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[1.571240971766251,1.5436638214051215,1.5640183847669076,1.5804333552199608,1.5745239658568613,1.5732107682206173,1.5594221930400525,1.57715036112935,1.577806959947472,1.5489166119500983],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9],\"y\":[1.571240971766251,1.571240971766251,1.571240971766251,1.5804333552199608,1.5804333552199608,1.5804333552199608,1.5804333552199608,1.5804333552199608,1.5804333552199608,1.5804333552199608],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3adcb385-a522-427a-b84e-a49431f798d7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storage = 'sqlite:///study.db'\n",
        "\n",
        "# Create a new study or load an existing one\n",
        "study = optuna.create_study(study_name='example_study', storage=storage, load_if_exists=True)\n",
        "\n",
        "# Now you can use the study for optimization\n",
        "def objective(trial):\n",
        "    x = trial.suggest_float('x', -10, 10)\n",
        "    return (x - 2) ** 2\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDalyYB6xIMf",
        "outputId": "e3e8cfc1-d47e-472d-8c42-d75d3e0bb372"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 12:21:02,470] A new study created in RDB with name: example_study\n",
            "[I 2024-06-28 12:21:02,568] Trial 0 finished with value: 5.763994488935476 and parameters: {'x': -0.40083204096735514}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,640] Trial 1 finished with value: 8.201261162347977 and parameters: {'x': -0.863784412686817}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,705] Trial 2 finished with value: 116.65486041766607 and parameters: {'x': -8.800687960387805}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,769] Trial 3 finished with value: 24.21941967064944 and parameters: {'x': -2.921322959393078}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,833] Trial 4 finished with value: 64.85417735133412 and parameters: {'x': -6.05320913371397}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,899] Trial 5 finished with value: 8.26151234638698 and parameters: {'x': -0.8742846669018327}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:02,962] Trial 6 finished with value: 38.06398217794333 and parameters: {'x': 8.16960146021956}. Best is trial 0 with value: 5.763994488935476.\n",
            "[I 2024-06-28 12:21:03,028] Trial 7 finished with value: 4.933301476158447 and parameters: {'x': 4.221103661731808}. Best is trial 7 with value: 4.933301476158447.\n",
            "[I 2024-06-28 12:21:03,090] Trial 8 finished with value: 21.367469890303568 and parameters: {'x': -2.62249606709444}. Best is trial 7 with value: 4.933301476158447.\n",
            "[I 2024-06-28 12:21:03,152] Trial 9 finished with value: 6.5931023063456315 and parameters: {'x': 4.56770370298943}. Best is trial 7 with value: 4.933301476158447.\n",
            "[I 2024-06-28 12:21:03,229] Trial 10 finished with value: 3.159414859868331 and parameters: {'x': 3.7774742923227698}. Best is trial 10 with value: 3.159414859868331.\n",
            "[I 2024-06-28 12:21:03,299] Trial 11 finished with value: 6.652834246673283 and parameters: {'x': 4.579308869963674}. Best is trial 10 with value: 3.159414859868331.\n",
            "[I 2024-06-28 12:21:03,372] Trial 12 finished with value: 3.7931208232006126 and parameters: {'x': 3.947593598059054}. Best is trial 10 with value: 3.159414859868331.\n",
            "[I 2024-06-28 12:21:03,439] Trial 13 finished with value: 52.41600776887146 and parameters: {'x': 9.239890038451652}. Best is trial 10 with value: 3.159414859868331.\n",
            "[I 2024-06-28 12:21:03,509] Trial 14 finished with value: 0.580993984459596 and parameters: {'x': 2.7622296140006606}. Best is trial 14 with value: 0.580993984459596.\n",
            "[I 2024-06-28 12:21:03,576] Trial 15 finished with value: 0.05053864691578075 and parameters: {'x': 1.7751919776436331}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,643] Trial 16 finished with value: 0.47304042665502777 and parameters: {'x': 1.312220655547851}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,710] Trial 17 finished with value: 0.25526444580607904 and parameters: {'x': 1.4947629805664682}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,777] Trial 18 finished with value: 19.41295606331923 and parameters: {'x': 6.406013624958419}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,842] Trial 19 finished with value: 51.94520461534476 and parameters: {'x': -5.207302173167485}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,909] Trial 20 finished with value: 21.504567134515142 and parameters: {'x': 6.6373017083768815}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:03,976] Trial 21 finished with value: 0.1085730275377048 and parameters: {'x': 1.6704957852504694}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,043] Trial 22 finished with value: 0.18033658049957463 and parameters: {'x': 1.5753394526217739}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,111] Trial 23 finished with value: 0.6266877717107207 and parameters: {'x': 1.2083638640696595}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,180] Trial 24 finished with value: 19.969609737430982 and parameters: {'x': -2.4687369286444896}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,256] Trial 25 finished with value: 0.15359538171641973 and parameters: {'x': 2.3919124669060934}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,335] Trial 26 finished with value: 14.4350278015021 and parameters: {'x': 5.799345707026685}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,408] Trial 27 finished with value: 0.5170203872445494 and parameters: {'x': 2.7190412973150773}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,481] Trial 28 finished with value: 2.842438276207516 and parameters: {'x': 0.3140467752017803}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,573] Trial 29 finished with value: 9.286061239060434 and parameters: {'x': -1.047303929551569}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,663] Trial 30 finished with value: 38.716604246722355 and parameters: {'x': -4.222266809348692}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,781] Trial 31 finished with value: 0.0767571035793422 and parameters: {'x': 2.2770507238383293}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,874] Trial 32 finished with value: 0.24631382750844533 and parameters: {'x': 2.4963001385335746}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:04,958] Trial 33 finished with value: 4.0259192240153805 and parameters: {'x': -0.006469342904441344}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,046] Trial 34 finished with value: 12.211874733558084 and parameters: {'x': -1.4945492890440226}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,130] Trial 35 finished with value: 130.31771329246777 and parameters: {'x': -9.415678398258589}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,216] Trial 36 finished with value: 0.25774293836635187 and parameters: {'x': 2.507683896106969}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,321] Trial 37 finished with value: 3.1138871682623077 and parameters: {'x': 0.23537902985873257}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,413] Trial 38 finished with value: 11.494602123635081 and parameters: {'x': 5.390369024698503}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,497] Trial 39 finished with value: 1.7872851836101817 and parameters: {'x': 3.3368938565234645}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,580] Trial 40 finished with value: 30.475223000799257 and parameters: {'x': 7.520436848728482}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,667] Trial 41 finished with value: 1.0026869204203588 and parameters: {'x': 0.9986574410221252}. Best is trial 15 with value: 0.05053864691578075.\n",
            "[I 2024-06-28 12:21:05,753] Trial 42 finished with value: 0.005530057320617254 and parameters: {'x': 1.9256356448248406}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:05,845] Trial 43 finished with value: 15.048612604673346 and parameters: {'x': -1.8792541299421655}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:05,938] Trial 44 finished with value: 6.07838827282899 and parameters: {'x': -0.46543875868555906}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,030] Trial 45 finished with value: 9.468271222972533 and parameters: {'x': 5.077055609340288}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,128] Trial 46 finished with value: 0.01324091858255071 and parameters: {'x': 1.8849308095859247}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,217] Trial 47 finished with value: 4.042329359587584 and parameters: {'x': 4.01055449057905}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,316] Trial 48 finished with value: 96.63146335646398 and parameters: {'x': -7.8301303834925795}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,414] Trial 49 finished with value: 1.7047211746183912 and parameters: {'x': 3.3056497135979432}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,512] Trial 50 finished with value: 0.005769216316079476 and parameters: {'x': 1.924044642611074}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,617] Trial 51 finished with value: 2.040403313634418 and parameters: {'x': 0.5715731332565821}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,711] Trial 52 finished with value: 0.06201117459000597 and parameters: {'x': 1.7509795699345012}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,813] Trial 53 finished with value: 0.02218630424493356 and parameters: {'x': 2.148950677222138}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,904] Trial 54 finished with value: 6.410134822987105 and parameters: {'x': -0.5318244060335435}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:06,979] Trial 55 finished with value: 2.3711149468240706 and parameters: {'x': 3.539842507149374}. Best is trial 42 with value: 0.005530057320617254.\n",
            "[I 2024-06-28 12:21:07,050] Trial 56 finished with value: 0.0004538667959297939 and parameters: {'x': 1.9786958502650354}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,120] Trial 57 finished with value: 1.5971483620768487 and parameters: {'x': 0.7362166474918066}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,188] Trial 58 finished with value: 6.240573698196707 and parameters: {'x': 4.498114028261462}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,257] Trial 59 finished with value: 0.006916499268472598 and parameters: {'x': 1.9168345067442476}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,338] Trial 60 finished with value: 1.0882956021953234 and parameters: {'x': 3.0432140730431714}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,405] Trial 61 finished with value: 0.0007690040488999008 and parameters: {'x': 2.0277309222511604}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,477] Trial 62 finished with value: 0.0076961118726459245 and parameters: {'x': 2.087727486414726}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,546] Trial 63 finished with value: 0.6550842344426591 and parameters: {'x': 1.190627258648613}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,615] Trial 64 finished with value: 3.6277086477836695 and parameters: {'x': 3.9046544693942966}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,682] Trial 65 finished with value: 4.063781425687397 and parameters: {'x': -0.015882294601397673}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,752] Trial 66 finished with value: 7.6130389642085605 and parameters: {'x': 4.759173601680141}. Best is trial 56 with value: 0.0004538667959297939.\n",
            "[I 2024-06-28 12:21:07,821] Trial 67 finished with value: 0.00020416415876298947 and parameters: {'x': 2.014288602407618}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:07,888] Trial 68 finished with value: 9.894557412655697 and parameters: {'x': -1.1455615417053435}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:07,959] Trial 69 finished with value: 1.149360528024413 and parameters: {'x': 3.0720823326705897}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,030] Trial 70 finished with value: 0.970493842788112 and parameters: {'x': 1.0148635410319482}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,101] Trial 71 finished with value: 0.002887624985676396 and parameters: {'x': 2.0537366261099113}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,169] Trial 72 finished with value: 0.007403139287200734 and parameters: {'x': 1.9139585025281363}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,241] Trial 73 finished with value: 2.151307748614449 and parameters: {'x': 0.5332662993527253}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,315] Trial 74 finished with value: 0.4262364201364881 and parameters: {'x': 2.6528678427802124}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,393] Trial 75 finished with value: 0.1361467014808195 and parameters: {'x': 1.6310193751959061}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,464] Trial 76 finished with value: 3.3668213436166776 and parameters: {'x': 3.8348900085881654}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,533] Trial 77 finished with value: 63.20681740315208 and parameters: {'x': 9.950271530152419}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,602] Trial 78 finished with value: 1.0523395458711804 and parameters: {'x': 3.0258360228960477}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,671] Trial 79 finished with value: 28.368395689398096 and parameters: {'x': -3.3261989907811462}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,738] Trial 80 finished with value: 4.922451252505579 and parameters: {'x': -0.21865978746304804}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,804] Trial 81 finished with value: 0.012160185075429484 and parameters: {'x': 1.8897267708125427}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,873] Trial 82 finished with value: 0.012098009701627714 and parameters: {'x': 2.1099909528171645}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:08,946] Trial 83 finished with value: 0.3351427882162042 and parameters: {'x': 1.421084817770164}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,018] Trial 84 finished with value: 0.2894834931663048 and parameters: {'x': 2.5380367024342343}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,085] Trial 85 finished with value: 1.4329114467609045 and parameters: {'x': 0.8029572076316969}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,150] Trial 86 finished with value: 5.468342271894544 and parameters: {'x': 4.338448689172919}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,218] Trial 87 finished with value: 0.5245623203808797 and parameters: {'x': 1.2757332532962185}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,286] Trial 88 finished with value: 0.044059406497481385 and parameters: {'x': 2.209903326551728}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,364] Trial 89 finished with value: 1.9448049626957562 and parameters: {'x': 3.3945626420838027}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,437] Trial 90 finished with value: 13.719345207614165 and parameters: {'x': 5.703963445771862}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,506] Trial 91 finished with value: 0.00021653208905122074 and parameters: {'x': 2.0147150293595093}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,576] Trial 92 finished with value: 0.9352104063873197 and parameters: {'x': 2.967062772723322}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,653] Trial 93 finished with value: 2.490555188606325 and parameters: {'x': 0.42185070775723976}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,720] Trial 94 finished with value: 0.01066024805186718 and parameters: {'x': 1.8967515227624776}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,790] Trial 95 finished with value: 0.26895527921023477 and parameters: {'x': 2.518608984891541}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,858] Trial 96 finished with value: 2.4839156171655428 and parameters: {'x': 3.576044294163569}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,928] Trial 97 finished with value: 0.2899440879155131 and parameters: {'x': 1.4615354348561893}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:09,996] Trial 98 finished with value: 0.9137369434378143 and parameters: {'x': 1.044104114750035}. Best is trial 67 with value: 0.00020416415876298947.\n",
            "[I 2024-06-28 12:21:10,065] Trial 99 finished with value: 3.5742796744085057 and parameters: {'x': 0.10942345449635238}. Best is trial 67 with value: 0.00020416415876298947.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "from optuna.storages import RDBStorage\n",
        "\n",
        "# Create the database engine\n",
        "engine = create_engine('sqlite:///study.db')\n",
        "\n",
        "# Use the RDBStorage with Optuna\n",
        "storage = RDBStorage(str(engine.url))\n",
        "\n",
        "# Create a study\n",
        "study = optuna.create_study(study_name='example_study', storage=storage, load_if_exists=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJjg3Kl8qSf-",
        "outputId": "834b3291-4176-4af5-8a5f-fbff7ab1bd44"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-28 12:22:58,435] Using an existing study with name 'example_study' instead of creating a new one.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "storage = optuna.storages.RDBStorage('sqlite:///study.db')\n",
        "storage.upgrade()"
      ],
      "metadata": {
        "id": "0_9Kxne7sjvW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!optuna-dashboard sqlite:///study.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWuEAACVss-E",
        "outputId": "c643c0a7-bbc2-4b1f-92b3-3e6a9a56bc28"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listening on http://127.0.0.1:8080/\n",
            "Hit Ctrl-C to quit.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/optuna-dashboard\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna_dashboard/_cli.py\", line 140, in main\n",
            "    run_wsgiref(app, args.host, args.port, args.quiet)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna_dashboard/_cli.py\", line 43, in run_wsgiref\n",
            "    httpd = make_server(host, port, app, server_class=ThreadedWSGIServer)\n",
            "  File \"/usr/lib/python3.10/wsgiref/simple_server.py\", line 154, in make_server\n",
            "    server = server_class((host, port), handler_class)\n",
            "  File \"/usr/lib/python3.10/socketserver.py\", line 452, in __init__\n",
            "    self.server_bind()\n",
            "  File \"/usr/lib/python3.10/wsgiref/simple_server.py\", line 50, in server_bind\n",
            "    HTTPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.10/http/server.py\", line 137, in server_bind\n",
            "    socketserver.TCPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.10/socketserver.py\", line 466, in server_bind\n",
            "    self.socket.bind(self.server_address)\n",
            "OSError: [Errno 98] Address already in use\n"
          ]
        }
      ]
    }
  ]
}